---
title: "Graphs and Language"
lastmod: "2024-02-15"
summary: >

categories:
  - ML
series:
  -
image: /images/graphs-and-language/talk.png
---

A rising tide lifts all boats, and the recent advances in LLMs are no exception.
In this blog post, we will explore how Knowledge Graphs can benefit from LLMs, and vice versa.

<figure>
  <img
    src="/images/graphs-and-language/KGs_and_LLMs.png"
    alt="Where do KGs fit with LLMs?"
  />
  <figcaption>
    Where do Knowledge Graphs fit with Large Language Models
  </figcaption>
</figure>

In particular, Knowledge Graphs can ground LLMs with facts using Graph RAG, which can be cheaper than Vector RAG.
We'll have a look at a 10 line code example in LlamaIndex, and see how easy it is to get started.
LLMs can help build automated KGs, which have been a bottleneck in the past.
And Graphs can provide your Domain Experts with an interface to supervise your AI systems.

_Note: this is a written version of a talk I gave at the [AI in Production online conference](https://home.mlops.community/home/events/ai-in-production-2024-02-15) on February 15th, 2024.
You can watch the talk here (link coming)._

<figure>
  <img src="/images/graphs-and-language/recap.png" alt="Talk overview" />
  <figcaption>Summary of the talk</figcaption>
</figure>

## A trip down memory lane at Spacy IRL 2019

I've been working with Natural Language Processing for a few years now, and I've seen the rise of Large Language Models.
The bulk of my NLP and Graphs work I did starting 2018, applied to the Sports Media domain, when I worked as Machine Learning Engineer at OneFootball, a football media company from Berlin, Germany.

As a practioner with a practical business use case, I remember that time well because it was a time of great change in the NLP field.
We were moving from the era of rule-based systems and word embeddings to the era of deep learning, moving from LSTMs to a slew of models like Elmo or ULMfit based on transformer architecture.
I was one of the lucky fews that could attend the [Spacy IRL 2019](https://irl.spacy.io/2019/) conference in Berlin.
There were corporate training workshops, as well as talks about Transformers, conversational AI assistants, and applied NLP in finance or media.

<div
  style={{
    display: "flex",
    justifyContent: "space-between",
  }}
>
  <figure style={{ width: "65%" }}>
    <img src="/images/graphs-and-language/spacy_irl.jpg" alt="Spacy IRL 2019" />
    <figcaption>Spacy IRL 2019</figcaption>
  </figure>
  <figure style={{ width: "30%" }}>
    <img
      src="/images/graphs-and-language/spacy_irl_louis.jpg"
      alt="Me at Spacy IRL"
    />
    <figcaption>
      Standing in the background, me at Spacy IRL, networking with a ghost
    </figcaption>
  </figure>
</div>

In his keynote, [The missing elements in NLP (spaCy IRL 2019)](https://www.youtube.com/watch?v=e12danHhlic),
Yoav Goldberg predicts that the next big thing in NLP will be to **enable non-experts to use NLP**, he was right ✅.
He thought we would get there by **humans writing rules aided by Deep Learning resulting in transparent and debuggable models**, he was wrong on that one ❌.
We got there with chat, and we now have less transparent and less debuggable models. In fact, we moved further right and down on his chart, to a place deeper than Deep Learning.
I believe, like him at the time, that there is still room to go to the bottom left.

<figure>
  <img
    src="/images/graphs-and-language/spacy_irl_keynote.png"
    alt="Spacy IRL Keynote"
  />
  <figcaption>
    Yoav Goldberg: The missing elements in NLP (spaCy IRL 2019)
  </figcaption>
</figure>

In the context of my employer at the time, OneFootball, a football media in 12 languages with 10 million monthly active users, we were using NLP to assist our newsroom and unlock new product features.
I built systems to extract entities and relations from football articles, tag the news, and recommend articles to users.
I talked about some of that work in a [previous talk](https://www.youtube.com/watch?v=QvNv402WBSY&t=1057s) at a Berlin NLP meetup.
We had medium data, not a lot. And we had partial labels in the form of "retags".
We also could not pay for much compute. So we had to be creative.
This was the realm of **Applied NLP**.

That's where I stumbled upon the beautiful world of Graphs, specifically the great work from my now friend [Paco Nathan](https://derwen.ai/paco)
with his library <em>[pytextrank](https://spacy.io/universe/project/spacy-pytextrank)</em>.
Graphs (along with rule-based matchers, weak supervision, and other NLP tricks I applied over the years) helped me
work with **little** annotated data, and incorporate **declarative knowledge** from domain experts,
while building a system that could be used and maintained by non-experts, with some level of **human+machine collaboration**.
We shipped a much better tagging system, a new recommendation system, and I was hooked.

Today with the rise of LLMs, I see a lot of potential to combine the two worlds of Graphs and LLMs, and I want to share that with you.

## 1. Fact grounding with Graph RAG

### 1.1 Fine-tuning vs Retrieval-Augmented Generation

The first place where Graphs and LLMs meet is in the area of fact grounding.
LLMs have been found to suffer from a few issues like hallucination, knowledge cut-off, bias, and lack of control.
In order to go around those issues, people have turned to their repositories of domain data.
And soon 2 approaches where in front of us: Fine Tuning or Retrieval-Augmented Generation (RAG).

In his talk at the AI Conference 3 months ago, [LLMs in Production](https://www.youtube.com/watch?v=xa7k9MUeIdk),
Dr. Waleed Kadous, Chief Scientist at AnyScale sheds some light on how to navigate the trade-offs between the two approaches.
**"Fine-tuning is for form, not facts"**, [he says](https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts). **"RAG is for facts"**.

Fine tuning will get easier and cheaper. Open source libraries like [OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
and [huggingface/trl](https://github.com/huggingface/trl) already make this process easier.
But it's still resource intensive and is something that requires more NLP maturity as a business. RAG is something that can be done today.

And according to this Hacker News thread from 2 months ago, [Ask HN: How do I train a custom LLM/ChatGPT on my own documents in Dec 2023?](https://news.ycombinator.com/item?id=38759877)
the vast majority of practitioners is indeed using RAG rather than fine-tuning.

### 1.2 Vector RAG vs Graph RAG

- the other thing is that Vector RAG is quite costly, let's look at this tutorial from NebulaGraph
- so first, there's not just 1 RAG; there's Structured vs Unstructured, Vector vs Graph etc... and your results depending on your architecture may vary
- and then, Graph RAG is more concise and cheaper

### 1.3 RAG Zoo

- I tried to make some diagrams to illustrate the differences and similarities of the RAG architectures
- in all cases, we ask a question in NL, we get an answer in NL, and a LLM is used to generate an answer
- but then they start to differ. On the top left Vector RAG embeds the query and retrieves documents from the Vector DB
- On the top right, Graph RAG extract keywords from the query and retrieves triples from the graph that match the keyword

### 1.4 Graph RAG implementation in LlamaIndex

- here is what we can do with current frameworks, in particular LlamaIndex
- that's 10 lines of python

## 2. KG construction

### 2.1 Building a Knowledge Graph

- the same way you build your Vector DB by chunking and embedding documents, you build your Graph by extracting Triples
- Usually, you either use a fine-tuned model specialised in RE like REBEL
- but people started using LLMs with prompt chains like "..."
- poor quality and lack of control

### 2.2 Building a KG in LlamaIndex

- again with 10 lines of python we get to a working system

### 2.3 Automated KG construction is not yet there

- but let's have a look at the results
- this is the Neo4j bloom screenshot of an extract of the KG you get by throwing the Wikipedia page from Guardians of the Galaxy vol 3 to our system
- Disambiguation issues between Nodes: Peter Quill and Quill are supposed to be the same
- Disambiguation issues between Relationships: play roles in = is part of cast in
- No information hierarchy: James Gunn is the director of the movie

- this is to be contrasted with what the Wikipedia KG looks like

  - Chris Pratt is the performer of Star-Lord
  - James Gunn is the director of the movies
  - the movies take place in the MCU of where Star Lord is present too

### 2.4 Towards better KG construction

- so where do we go from there?
- here are a couple of libraries that are worth having a look at: textgraphs by Paco Nathan and zshot by IBM
- Get better entities, get better relations, enable HITL systems by integrating with Graph DBs

## 3. Unlock Experts

### 3.1 Human vs AI

The final place where Graphs and LLMs meet is in the area of Human+Machine collaboration.
Who doesn't love a "Human vs AI" story? News headlines about "AGI" or "ChatGPT passing the bar exam" are everywhere.

<figure style={{ width: "50%" }}>
  <img src="/images/graphs-and-language/human_vs_ai.png" alt="Human vs AI" />
  <figcaption>Human vs AI news headlines</figcaption>
</figure>

I would encourage the reader to have a look at [this answer](https://aisnakeoil.com/p/gpt-4-and-professional-benchmarks) from the AI Snake Oil newsletter.
They make a good point that models like ChatGPT **memorise the solutions rather than reason** about them, which make exams a bad way to compare humans with machines.

Goying beyond Memorisation, there is a whole area of research around what's called
Generalization, **Reasoning, Planning, Representation Learning**, and graphs can help with that.

### 3.2 Human + Machine: Visualisation

Rather than against each other, I'm interested in ways Humans and Machines can work together.
In particular, how do humans **understand and debug black-box models**?

One key project that, in my opinion, moved the needle there was the [whatlies paper](https://arxiv.org/abs/2009.02113) from Vincent Warmerdam, 2020.
He used UMAP on embeddings to reveal quality issues in LLMs, and built a framework for others to audit their embeddings rather than blindly trust them.

Similarly, Graph Databases come with a lot of visualisation tools out of the box. For example, they would add context with
color, metadata, and different layout algorithms (force-based, sankey).

<div
  style={{
    display: "flex",
    justifyContent: "space-between",
  }}
>
  <figure style={{ width: "45%" }}>
    <img src="/images/graphs-and-language/whatlies.jpg" alt="Whatlies" />
    <figcaption>Warmerdam, 2020: whatlies in embeddings</figcaption>
  </figure>
  <figure style={{ width: "45%" }}>
    <img src="/images/graphs-and-language/neo4j.png" alt="Neo4j Bloom" />
    <figcaption>Neo4j Bloom</figcaption>
  </figure>
</div>

### 3.3 Human + Machine: Human in the Loop

Finally, how do we **address the lack of control** of Deep Learning models, and how do we **incorporate declarative knowledge** from domain experts?

I like to refer to the phrase "the proof is in the pudding", and by that I mean that the value of a piece of tech must be judged based on its results in production.
And when we look at production systems, we see that LLMs or Deep Learning models are not used in isolation, but rather within **Human-in-the-Loop systems**.

In a [project](https://security.googleblog.com/2024/01/scaling-security-with-ai-from-detection.html) and [paper](https://storage.googleapis.com/gweb-research2023-media/pubtools/pdf/4fd3441fe40bb74e3f94f5203a17399af07b115c.pdf) from 2 weeks ago,
Google has started using language models to help it find and spot bugs in its C/C++, Java, and Go code.
The results have been encouraging: it has recently started using an LLM based on its Gemini model to
“successfully fix 15% of sanitizer bugs discovered during unit tests, resulting in hundreds of bugs patched”.
Though the 15% acceptance rate sounds relatively small, it has a big effect at Google-scale.
The bug pipeline yields better-than-human fixes - “approximately 95% of the commits sent to code owners
were accepted without discussion,” Google writes. “This was a higher acceptance rate than human-generated
code changes, which often provoke questions and comments”.

The key takeway here for me has to do with their architecture:

<figure>
  <img
    src="/images/graphs-and-language/google_project.png"
    alt="AI-powered patching"
  />
  <figcaption>AI-powered patching at Google</figcaption>
</figure>

They built it with a LLM, but they also combined LLMs with smaller more specific AI models,
and more importantly with a double human filter on top, thus working with machines.

## Conclusion

{/* jacques cousteau quote? */}
I presented here a few ways in which Graphs and LLMs can work together.
I remember those days from 2019 vividly, and although we've gone one level deeper into the abyss of Deep Learning,
I believe there is still room for innovation to let Humans use NLP systems without expertise, with more control, and with more transparency.

Graphs can hopefully help with that, as they have in the past, and I'm excited to see what the future holds.

## Resources

1. [My link](url)

## Checklist before publication

- Review Headlines: Talk benefits, not details. Keep it short
- Review Content skimming: Break it down with bullet points, bolding, spacing
- Review Story: do I have a beginning, a middle, and end? do I tell my emotions?
  e.g. storyline of a side project: life before the solution / my approach to solving it / complications I faced / end results / what would I do differently
